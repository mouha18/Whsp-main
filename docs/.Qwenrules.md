# Qwen Coding Rules

## General Principles
- Write clean, readable, and minimal code.
- Prefer clarity over cleverness.
- Optimize logic for low-latency inference (Qwen 2.5 1.5B model).
- Avoid unnecessary abstractions.
- Always handle failure states explicitly.

## Language & Framework Rules
- Frontend: TypeScript + React (Next.js App Router)
- Backend: Node.js (Express)
- AI Processing: Python microservice (FastAPI)
- Speech-to-Text: faster-whisper
- Summarization: Qwen 2.5 1.5B
- Follow functional programming where possible.
- Avoid class-heavy patterns unless necessary.

## Naming Conventions
- Files: kebab-case (e.g., `audio-processor.ts`)
- React Components: PascalCase (e.g., `TranscriptViewer.tsx`)
- Variables & Functions: camelCase
- Constants: SCREAMING_SNAKE_CASE
- API routes: RESTful and noun-based (`/api/transcripts`)

## UI / UX Rules
- Mobile-first design.
- Minimalist UI, no visual clutter.
- Clear mode selection: Lecture / Meeting / Interview / Custom.
- Real-time feedback for recording and processing states.
- Always show:
  - Recording status
  - Processing status
  - Confidence indicator for transcript quality

## AI-Specific Rules
- Chunk audio into 30–60s segments before inference.
- **Audio Preprocessing Pipeline**:
  - Convert to mono WAV (16kHz)
  - Noise reduction using spectral gating
  - Silence trimming via RMS threshold
  - **Fallback**: If preprocessing fails, raw audio proceeds to transcription
- **Model Responsibilities**:
  - faster-whisper: Speech-to-text transcription only
  - Qwen 2.5 1.5B: Transcript cleanup and summarization only
- **Sequential Processing**: No parallel inference, strict order maintained
- **Transcript Cleanup Rules**:
  - Remove filler words (e.g., "um", "uh", "like", "you know")
  - Collapse repeated phrases and redundant expressions
  - Prioritize intent preservation over grammatical perfection
  - Raw transcript always preserved and accessible
- **Mode-Aware Summarization**:
  - Lecture: structured notes with concepts and definitions
  - Meeting: decisions and action items extraction
  - Interview: Q/A extraction and speaker intent
  - Custom: structured options only (tone, format, focus areas)
- **Confidence Scoring**: Average token probability, informational only (not used for blocking)
- **Error Recovery**: Each pipeline stage retryable independently, maximum 2 retries per stage
- **Fallback Handling**: Partial results returned with warnings if failure persists
- Never hallucinate missing audio content.
- Summaries must be mode-aware (Lecture ≠ Meeting).

## Error Handling
- Fail gracefully with user-readable messages.
- Log full error context server-side.
- **Retry Logic**: Each pipeline stage retryable independently, maximum 2 retries per stage
- **Partial Results**: Return partial results with warnings if failure persists
- **Error Types**:
  - Processing failure with attempt tracking
  - Authentication errors (deployable version)
  - Database errors with detailed messages
  - Storage errors with fallback options
  - AI service errors with stage identification

## Output Rules
- Generated documents must support:
  - `.docx`
  - `.md`
  - `.pdf`
- Ensure formatting consistency across formats.
- **Storage Strategy**:
  - Local: filesystem storage (`/data/{recording_uuid}/`)
  - Cloud: Supabase Storage buckets
  - Database stores file references only
- **Export Security**: Signed URLs only for file downloads
- **Dual Deployment Support**:
  - Local version: PostgreSQL database, no authentication
  - Deployable version: Supabase with Google Auth integration
- **Token Limits**:
  - Lecture: 400 tokens
  - Meeting: 300 tokens
  - Interview: 350 tokens
  - Custom: 500 tokens
